summarise(unique_bigrams = n_distinct(ngram))
sentence_tokenized <- analysis.data %>%
unnest_tokens(sentence, transcription, token = "sentences")
sentence_tokenized %>%
group_by(medical_specialty) %>%
summarise(unique_sentences = n_distinct(sentence))
tokenized.data %>%
dplyr::group_by(medical_specialty) %>%
dplyr::count(ngram, sort = TRUE) %>%
dplyr::top_n(5)
lemmatized.data <- tokenized.data %>% dplyr::mutate(lemma=textstem::lemmatize_words(ngram))
lemma.freq <- lemmatized.data %>%
dplyr::count(medical_specialty, lemma) %>%
dplyr::group_by(medical_specialty) %>%
dplyr::mutate(proportion = n / sum(n)) %>%
tidyr::pivot_wider(names_from = medical_specialty, values_from = proportion) %>%
tidyr::pivot_longer(`Surgery`:`Radiology`,
names_to = "medical_specialty", values_to = "proportion")
ggplot2::ggplot(lemma.freq, ggplot2::aes(x=proportion,
y=`Orthopedic`,
color=abs(`Orthopedic` - proportion))) +
ggplot2::geom_abline(color="gray40", lty=2) +
ggplot2::geom_jitter(alpha=0.1, size=2.5, width=0.3, height=0.3) +
ggplot2::geom_text(ggplot2::aes(label=lemma), check_overlap=TRUE, vjust=1.5) +
ggplot2::scale_x_log10(labels=scales::percent_format()) +
ggplot2::scale_y_log10(labels=scales::percent_format()) +
ggplot2::scale_color_gradient(limits=c(0, 0.001), low="darkslategray4", high="gray75") +
ggplot2::facet_wrap(~medical_specialty, ncol = 2) +
ggplot2::theme(legend.position="none") +
ggplot2:: labs(y="Orthopedic", x = NULL)
lemma.counts <- lemmatized.data %>% dplyr::count(medical_specialty, lemma)
total.counts <- lemma.counts %>%
dplyr::group_by(medical_specialty) %>%
dplyr::summarise(total=sum(n))
all.counts <- dplyr::left_join(lemma.counts, total.counts)
all.counts.tfidf <- tidytext::bind_tf_idf(all.counts, lemma, medical_specialty, n)
all.counts.tfidf %>% dplyr::group_by(medical_specialty) %>% dplyr::slice_max(order_by=tf_idf, n=10)
analysis.data %>% dplyr::select(medical_specialty, transcription) %>% dplyr::filter(stringr::str_detect(transcription, 'steri strips')) %>% dplyr::slice(1)
analysis.data %>%
select(medical_specialty, transcription) %>%
filter(str_detect(transcription, "arthroscopic")) %>%
slice(1)
lemma.counts <- lemmatized.data %>% dplyr::count(note_id, lemma)
total.counts <- lemma.counts %>%
dplyr::group_by(note_id) %>%
dplyr::summarise(total=sum(n))
all.counts <- dplyr::left_join(lemma.counts, total.counts)
emr.dcm <- all.counts %>% tidytext::cast_dtm(note_id, lemma, n)
emr.lda <- topicmodels::LDA(emr.dcm, k=5, control=list(seed=42))
emr.topics <- tidytext::tidy(emr.lda, matrix='beta')
top.terms <- emr.topics %>% dplyr::group_by(topic) %>%
dplyr::slice_max(beta, n=10) %>%
dplyr::ungroup() %>%
dplyr::arrange(topic, -beta)
top.terms %>%
dplyr::mutate(term=tidytext::reorder_within(term, beta, topic)) %>%
ggplot2::ggplot(ggplot2::aes(beta, term, fill=factor(topic))) +
ggplot2::geom_col(show.legend=FALSE) +
ggplot2::facet_wrap(~ topic, scales='free')  +
ggplot2::theme(axis.text.x = element_text(angle = 45,vjust = 1,hjust = 1)) +
tidytext::scale_y_reordered()
specialty_gamma <- tidytext::tidy(emr.lda, matrix='gamma')
# we need to join in the specialty from the note_id
note_id_specialty_mapping <- lemmatized.data %>%
dplyr::mutate(document=as.character(note_id)) %>%
dplyr::select(document, medical_specialty) %>%
dplyr::distinct()
specialty_gamma <- dplyr::left_join(specialty_gamma, note_id_specialty_mapping)
specialty_gamma %>%
dplyr::mutate(medical_specialty = reorder(medical_specialty, gamma * topic)) %>%
ggplot2::ggplot(ggplot2::aes(factor(topic), gamma)) +
ggplot2::geom_boxplot() +
ggplot2::facet_wrap(~ medical_specialty) +
ggplot2::labs(x = "topic", y = expression(gamma))
emr.lda_6 <- topicmodels::LDA(emr.dcm, k=6, control=list(seed=42))
emr.topics_6 <- tidytext::tidy(emr.lda_6, matrix='beta')
top.terms_6 <- emr.topics_6 %>%
group_by(topic) %>%
slice_max(beta, n=10) %>%
ungroup()
top.terms_6 %>%
mutate(term = tidytext::reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = 'free') +
tidytext::scale_y_reordered()
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(tidytext)
library(textstem)
library(clinspacy)
library(topicmodels)
library('reshape2')
library(stringr)
raw.data <- clinspacy::dataset_mtsamples()
dplyr::glimpse(raw.data)
analysis.data <- filtered.data %>%
unnest_tokens(word, transcription) %>%
mutate(word = str_replace_all(word, "[^[:alnum:]]", "")) %>%
filter(!str_detect(word, "[0-9]")) %>%
anti_join(stop_words) %>%
group_by(note_id) %>%
summarise(transcription = paste(word, collapse = " ")) %>%
left_join(select(filtered.data, -transcription), by = "note_id")
View(analysis.data)
View(raw.data)
View(filtered.data)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(tidytext)
library(textstem)
library(clinspacy)
library(topicmodels)
library('reshape2')
library(stringr)
raw.data <- clinspacy::dataset_mtsamples()
dplyr::glimpse(raw.data)
raw.data %>% dplyr::select(medical_specialty) %>% dplyr::n_distinct()
ggplot2::ggplot(raw.data, ggplot2::aes(y=medical_specialty)) + ggplot2::geom_bar() + labs(x="Document Count", y="Medical Speciality")
filtered.data <- raw.data %>% dplyr::filter(medical_specialty %in% c("Orthopedic", "Radiology", "Surgery"))
analysis.data <- filtered.data %>%
unnest_tokens(word, transcription) %>%
mutate(word = str_replace_all(word, "[^[:alnum:]]", "")) %>%
filter(!str_detect(word, "[0-9]")) %>%
anti_join(stop_words) %>%
group_by(note_id) %>%
summarise(transcription = paste(word, collapse = " ")) %>%
left_join(select(filtered.data, -transcription), by = "note_id")
tokenized.data.unigram <- analysis.data %>% tidytext::unnest_tokens(word, transcription, to_lower=TRUE)
tokenized.data <- analysis.data %>% tidytext::unnest_tokens(ngram, transcription, token = "ngrams", n=2, to_lower = TRUE)
tidytext::stop_words %>% dplyr::group_by(lexicon) %>% dplyr::distinct(word) %>% dplyr::summarise(n=dplyr::n())
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(tidytext)
library(textstem)
library(clinspacy)
library(topicmodels)
library('reshape2')
library(stringr)
raw.data <- clinspacy::dataset_mtsamples()
dplyr::glimpse(raw.data)
raw.data %>% dplyr::select(medical_specialty) %>% dplyr::n_distinct()
ggplot2::ggplot(raw.data, ggplot2::aes(y=medical_specialty)) + ggplot2::geom_bar() + labs(x="Document Count", y="Medical Speciality")
filtered.data <- raw.data %>% dplyr::filter(medical_specialty %in% c("Orthopedic", "Radiology", "Surgery"))
analysis.data <- filtered.data %>%
unnest_tokens(word, transcription) %>%
mutate(word = str_replace_all(word, "[^[:alnum:]]", "")) %>%
filter(!str_detect(word, "[0-9]")) %>%
anti_join(stop_words) %>%
group_by(note_id) %>%
summarise(transcription = paste(word, collapse = " ")) %>%
left_join(select(filtered.data, -transcription), by = "note_id")
tokenized.data.unigram <- analysis.data %>% tidytext::unnest_tokens(word, transcription, to_lower=TRUE)
tokenized.data <- analysis.data %>% tidytext::unnest_tokens(ngram, transcription, token = "ngrams", n=2, to_lower = TRUE)
tidytext::stop_words %>% dplyr::group_by(lexicon) %>% dplyr::distinct(word) %>% dplyr::summarise(n=dplyr::n())
tokenized.data.unigram %>%
group_by(medical_specialty) %>%
summarise(unique_unigrams = n_distinct(word))
word_counts <- tokenized.data.unigram %>%
group_by(word) %>%
summarise(count = n()) %>%
ungroup() %>%
arrange(desc(count))
count_distribution <- word_counts %>%
group_by(count) %>%
summarise(num_words = n()) %>%
ungroup()
ggplot2::ggplot(count_distribution, aes(x = count, y = num_words)) +
geom_point() +
labs(title = "Scatter Plot of Count Distribution",
x = "Count of Unique Words",
y = "Number of Words")
word_counts <- tokenized.data %>%
group_by(ngram) %>%
summarise(count = n()) %>%
ungroup() %>%
arrange(desc(count))
count_distribution <- word_counts %>%
group_by(count) %>%
summarise(num_words = n()) %>%
ungroup()
ggplot2::ggplot(count_distribution, aes(x = count, y = num_words)) +
geom_point() +
labs(title = "Scatter Plot of Count Distribution",
x = "Count of Unique Bigrams",
y = "Number of Words")
tokenized.data %>%
group_by(medical_specialty) %>%
summarise(unique_bigrams = n_distinct(ngram))
sentence_tokenized <- analysis.data %>%
unnest_tokens(sentence, transcription, token = "sentences")
sentence_tokenized %>%
group_by(medical_specialty) %>%
summarise(unique_sentences = n_distinct(sentence))
tokenized.data %>%
dplyr::group_by(medical_specialty) %>%
dplyr::count(ngram, sort = TRUE) %>%
dplyr::top_n(5)
lemmatized.data <- tokenized.data %>% dplyr::mutate(lemma=textstem::lemmatize_words(ngram))
lemma.freq <- lemmatized.data %>%
dplyr::count(medical_specialty, lemma) %>%
dplyr::group_by(medical_specialty) %>%
dplyr::mutate(proportion = n / sum(n)) %>%
tidyr::pivot_wider(names_from = medical_specialty, values_from = proportion) %>%
tidyr::pivot_longer(`Surgery`:`Radiology`,
names_to = "medical_specialty", values_to = "proportion")
ggplot2::ggplot(lemma.freq, ggplot2::aes(x=proportion,
y=`Orthopedic`,
color=abs(`Orthopedic` - proportion))) +
ggplot2::geom_abline(color="gray40", lty=2) +
ggplot2::geom_jitter(alpha=0.1, size=2.5, width=0.3, height=0.3) +
ggplot2::geom_text(ggplot2::aes(label=lemma), check_overlap=TRUE, vjust=1.5) +
ggplot2::scale_x_log10(labels=scales::percent_format()) +
ggplot2::scale_y_log10(labels=scales::percent_format()) +
ggplot2::scale_color_gradient(limits=c(0, 0.001), low="darkslategray4", high="gray75") +
ggplot2::facet_wrap(~medical_specialty, ncol = 2) +
ggplot2::theme(legend.position="none") +
ggplot2:: labs(y="Orthopedic", x = NULL)
# Create wide-format lemma proportions
lemma.freq.wide <- lemmatized.data %>%
count(medical_specialty, lemma) %>%
group_by(medical_specialty) %>%
mutate(proportion = n / sum(n)) %>%
select(medical_specialty, lemma, proportion) %>%
pivot_wider(names_from = medical_specialty, values_from = proportion, values_fill = 0)
# Filter to only terms that exist in both
lemma.freq.filtered <- lemma.freq.wide %>%
filter(Surgery > 0 & Radiology > 0)
# Plot Surgery vs Radiology directly
ggplot(lemma.freq.filtered, aes(x = Surgery, y = Radiology,
color = abs(Surgery - Radiology))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = lemma), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = scales::percent_format()) +
scale_y_log10(labels = scales::percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
labs(x = "Surgery", y = "Radiology", title = "Lemma Frequency Comparison") +
theme(legend.position = "none")
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(tidytext)
library(textstem)
library(clinspacy)
library(topicmodels)
library('reshape2')
library(stringr)
raw.data <- clinspacy::dataset_mtsamples()
dplyr::glimpse(raw.data)
raw.data %>% dplyr::select(medical_specialty) %>% dplyr::n_distinct()
ggplot2::ggplot(raw.data, ggplot2::aes(y=medical_specialty)) + ggplot2::geom_bar() + labs(x="Document Count", y="Medical Speciality")
filtered.data <- raw.data %>% dplyr::filter(medical_specialty %in% c("Orthopedic", "Radiology", "Surgery"))
analysis.data <- filtered.data %>%
unnest_tokens(word, transcription) %>%
mutate(word = str_replace_all(word, "[^[:alnum:]]", "")) %>%
filter(!str_detect(word, "[0-9]")) %>%
anti_join(stop_words) %>%
group_by(note_id) %>%
summarise(transcription = paste(word, collapse = " ")) %>%
left_join(select(filtered.data, -transcription), by = "note_id")
tokenized.data.unigram <- analysis.data %>% tidytext::unnest_tokens(word, transcription, to_lower=TRUE)
tokenized.data <- analysis.data %>% tidytext::unnest_tokens(ngram, transcription, token = "ngrams", n=2, to_lower = TRUE)
tidytext::stop_words %>% dplyr::group_by(lexicon) %>% dplyr::distinct(word) %>% dplyr::summarise(n=dplyr::n())
word_counts <- tokenized.data.unigram %>%
group_by(word) %>%
summarise(count = n()) %>%
ungroup() %>%
arrange(desc(count))
count_distribution <- word_counts %>%
group_by(count) %>%
summarise(num_words = n()) %>%
ungroup()
ggplot2::ggplot(count_distribution, aes(x = count, y = num_words)) +
geom_point() +
labs(title = "Scatter Plot of Count Distribution",
x = "Count of Unique Words",
y = "Number of Words")
word_counts <- tokenized.data %>%
group_by(ngram) %>%
summarise(count = n()) %>%
ungroup() %>%
arrange(desc(count))
count_distribution <- word_counts %>%
group_by(count) %>%
summarise(num_words = n()) %>%
ungroup()
ggplot2::ggplot(count_distribution, aes(x = count, y = num_words)) +
geom_point() +
labs(title = "Scatter Plot of Count Distribution",
x = "Count of Unique Bigrams",
y = "Number of Words")
tokenized.data %>%
dplyr::group_by(medical_specialty) %>%
dplyr::count(ngram, sort = TRUE) %>%
dplyr::top_n(5)
lemmatized.data <- tokenized.data %>% dplyr::mutate(lemma=textstem::lemmatize_words(ngram))
lemma.freq <- lemmatized.data %>%
dplyr::count(medical_specialty, lemma) %>%
dplyr::group_by(medical_specialty) %>%
dplyr::mutate(proportion = n / sum(n)) %>%
tidyr::pivot_wider(names_from = medical_specialty, values_from = proportion) %>%
tidyr::pivot_longer(`Surgery`:`Radiology`,
names_to = "medical_specialty", values_to = "proportion")
ggplot2::ggplot(lemma.freq, ggplot2::aes(x=proportion,
y=`Orthopedic`,
color=abs(`Orthopedic` - proportion))) +
ggplot2::geom_abline(color="gray40", lty=2) +
ggplot2::geom_jitter(alpha=0.1, size=2.5, width=0.3, height=0.3) +
ggplot2::geom_text(ggplot2::aes(label=lemma), check_overlap=TRUE, vjust=1.5) +
ggplot2::scale_x_log10(labels=scales::percent_format()) +
ggplot2::scale_y_log10(labels=scales::percent_format()) +
ggplot2::scale_color_gradient(limits=c(0, 0.001), low="darkslategray4", high="gray75") +
ggplot2::facet_wrap(~medical_specialty, ncol = 2) +
ggplot2::theme(legend.position="none") +
ggplot2:: labs(y="Orthopedic", x = NULL)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(tidytext)
library(textstem)
library(clinspacy)
library(topicmodels)
library('reshape2')
library(stringr)
raw.data <- clinspacy::dataset_mtsamples()
dplyr::glimpse(raw.data)
raw.data %>% dplyr::select(medical_specialty) %>% dplyr::n_distinct()
ggplot2::ggplot(raw.data, ggplot2::aes(y=medical_specialty)) + ggplot2::geom_bar() + labs(x="Document Count", y="Medical Speciality")
filtered.data <- raw.data %>% dplyr::filter(medical_specialty %in% c("Orthopedic", "Radiology", "Surgery"))
analysis.data <- filtered.data %>%
unnest_tokens(word, transcription) %>%
mutate(word = str_replace_all(word, "[^[:alnum:]]", "")) %>%
filter(!str_detect(word, "[0-9]")) %>%
anti_join(stop_words) %>%
group_by(note_id) %>%
summarise(transcription = paste(word, collapse = " ")) %>%
left_join(select(filtered.data, -transcription), by = "note_id")
tokenized.data.unigram <- analysis.data %>% tidytext::unnest_tokens(word, transcription, to_lower=TRUE)
tokenized.data <- analysis.data %>% tidytext::unnest_tokens(ngram, transcription, token = "ngrams", n=2, to_lower = TRUE)
tidytext::stop_words %>% dplyr::group_by(lexicon) %>% dplyr::distinct(word) %>% dplyr::summarise(n=dplyr::n())
tokenized.data.unigram %>%
group_by(medical_specialty) %>%
summarise(unique_unigrams = n_distinct(word))
word_counts <- tokenized.data.unigram %>%
group_by(word) %>%
summarise(count = n()) %>%
ungroup() %>%
arrange(desc(count))
count_distribution <- word_counts %>%
group_by(count) %>%
summarise(num_words = n()) %>%
ungroup()
ggplot2::ggplot(count_distribution, aes(x = count, y = num_words)) +
geom_point() +
labs(title = "Scatter Plot of Count Distribution",
x = "Count of Unique Words",
y = "Number of Words")
word_counts <- tokenized.data %>%
group_by(ngram) %>%
summarise(count = n()) %>%
ungroup() %>%
arrange(desc(count))
count_distribution <- word_counts %>%
group_by(count) %>%
summarise(num_words = n()) %>%
ungroup()
ggplot2::ggplot(count_distribution, aes(x = count, y = num_words)) +
geom_point() +
labs(title = "Scatter Plot of Count Distribution",
x = "Count of Unique Bigrams",
y = "Number of Words")
tokenized.data %>%
group_by(medical_specialty) %>%
summarise(unique_bigrams = n_distinct(ngram))
sentence_tokenized <- analysis.data %>%
unnest_tokens(sentence, transcription, token = "sentences")
sentence_tokenized %>%
group_by(medical_specialty) %>%
summarise(unique_sentences = n_distinct(sentence))
tokenized.data %>%
dplyr::group_by(medical_specialty) %>%
dplyr::count(ngram, sort = TRUE) %>%
dplyr::top_n(5)
lemmatized.data <- tokenized.data %>% dplyr::mutate(lemma=textstem::lemmatize_words(ngram))
lemma.freq <- lemmatized.data %>%
dplyr::count(medical_specialty, lemma) %>%
dplyr::group_by(medical_specialty) %>%
dplyr::mutate(proportion = n / sum(n)) %>%
tidyr::pivot_wider(names_from = medical_specialty, values_from = proportion) %>%
tidyr::pivot_longer(`Surgery`:`Radiology`,
names_to = "medical_specialty", values_to = "proportion")
ggplot2::ggplot(lemma.freq, ggplot2::aes(x=proportion,
y=`Orthopedic`,
color=abs(`Orthopedic` - proportion))) +
ggplot2::geom_abline(color="gray40", lty=2) +
ggplot2::geom_jitter(alpha=0.1, size=2.5, width=0.3, height=0.3) +
ggplot2::geom_text(ggplot2::aes(label=lemma), check_overlap=TRUE, vjust=1.5) +
ggplot2::scale_x_log10(labels=scales::percent_format()) +
ggplot2::scale_y_log10(labels=scales::percent_format()) +
ggplot2::scale_color_gradient(limits=c(0, 0.001), low="darkslategray4", high="gray75") +
ggplot2::facet_wrap(~medical_specialty, ncol = 2) +
ggplot2::theme(legend.position="none") +
ggplot2:: labs(y="Orthopedic", x = NULL)
# Create wide-format lemma proportions
lemma.freq.wide <- lemmatized.data %>%
count(medical_specialty, lemma) %>%
group_by(medical_specialty) %>%
mutate(proportion = n / sum(n)) %>%
select(medical_specialty, lemma, proportion) %>%
pivot_wider(names_from = medical_specialty, values_from = proportion, values_fill = 0)
# Filter to only terms that exist in both
lemma.freq.filtered <- lemma.freq.wide %>%
filter(Surgery > 0 & Radiology > 0)
# Plot Surgery vs Radiology directly
ggplot(lemma.freq.filtered, aes(x = Surgery, y = Radiology,
color = abs(Surgery - Radiology))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = lemma), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = scales::percent_format()) +
scale_y_log10(labels = scales::percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
labs(x = "Surgery", y = "Radiology", title = "Lemma Frequency Comparison") +
theme(legend.position = "none")
lemma.counts <- lemmatized.data %>% dplyr::count(medical_specialty, lemma)
total.counts <- lemma.counts %>%
dplyr::group_by(medical_specialty) %>%
dplyr::summarise(total=sum(n))
all.counts <- dplyr::left_join(lemma.counts, total.counts)
all.counts.tfidf <- tidytext::bind_tf_idf(all.counts, lemma, medical_specialty, n)
all.counts.tfidf %>% dplyr::group_by(medical_specialty) %>% dplyr::slice_max(order_by=tf_idf, n=10)
analysis.data %>% dplyr::select(medical_specialty, transcription) %>% dplyr::filter(stringr::str_detect(transcription, 'steri strips')) %>% dplyr::slice(1)
analysis.data %>%
select(medical_specialty, transcription) %>%
filter(str_detect(transcription, "arthroscopic")) %>%
slice(1)
lemma.counts <- lemmatized.data %>% dplyr::count(note_id, lemma)
total.counts <- lemma.counts %>%
dplyr::group_by(note_id) %>%
dplyr::summarise(total=sum(n))
all.counts <- dplyr::left_join(lemma.counts, total.counts)
emr.dcm <- all.counts %>% tidytext::cast_dtm(note_id, lemma, n)
emr.lda <- topicmodels::LDA(emr.dcm, k=5, control=list(seed=42))
emr.topics <- tidytext::tidy(emr.lda, matrix='beta')
top.terms <- emr.topics %>% dplyr::group_by(topic) %>%
dplyr::slice_max(beta, n=10) %>%
dplyr::ungroup() %>%
dplyr::arrange(topic, -beta)
top.terms %>%
dplyr::mutate(term=tidytext::reorder_within(term, beta, topic)) %>%
ggplot2::ggplot(ggplot2::aes(beta, term, fill=factor(topic))) +
ggplot2::geom_col(show.legend=FALSE) +
ggplot2::facet_wrap(~ topic, scales='free')  +
ggplot2::theme(axis.text.x = element_text(angle = 45,vjust = 1,hjust = 1)) +
tidytext::scale_y_reordered()
specialty_gamma <- tidytext::tidy(emr.lda, matrix='gamma')
# we need to join in the specialty from the note_id
note_id_specialty_mapping <- lemmatized.data %>%
dplyr::mutate(document=as.character(note_id)) %>%
dplyr::select(document, medical_specialty) %>%
dplyr::distinct()
specialty_gamma <- dplyr::left_join(specialty_gamma, note_id_specialty_mapping)
specialty_gamma %>%
dplyr::mutate(medical_specialty = reorder(medical_specialty, gamma * topic)) %>%
ggplot2::ggplot(ggplot2::aes(factor(topic), gamma)) +
ggplot2::geom_boxplot() +
ggplot2::facet_wrap(~ medical_specialty) +
ggplot2::labs(x = "topic", y = expression(gamma))
emr.lda_6 <- topicmodels::LDA(emr.dcm, k=6, control=list(seed=42))
emr.topics_6 <- tidytext::tidy(emr.lda_6, matrix='beta')
top.terms_6 <- emr.topics_6 %>%
group_by(topic) %>%
slice_max(beta, n=10) %>%
ungroup()
top.terms_6 %>%
mutate(term = tidytext::reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = 'free') +
tidytext::scale_y_reordered()
specialty_gamma <- tidytext::tidy(emr.lda_6, matrix='gamma')
# we need to join in the specialty from the note_id
note_id_specialty_mapping <- lemmatized.data %>%
dplyr::mutate(document=as.character(note_id)) %>%
dplyr::select(document, medical_specialty) %>%
dplyr::distinct()
specialty_gamma <- dplyr::left_join(specialty_gamma, note_id_specialty_mapping)
specialty_gamma %>%
dplyr::mutate(medical_specialty = reorder(medical_specialty, gamma * topic)) %>%
ggplot2::ggplot(ggplot2::aes(factor(topic), gamma)) +
ggplot2::geom_boxplot() +
ggplot2::facet_wrap(~ medical_specialty) +
ggplot2::labs(x = "topic", y = expression(gamma))
